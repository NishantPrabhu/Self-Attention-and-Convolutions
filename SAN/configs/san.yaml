
# Configuration for SAN models

epochs: 300
batch_size: 64
eval_every: 10

# Models
encoder:
  attention: channel
  num_encoder_blocks: 6
  num_heads: 1
  model_dim: 128
  ff_dim: 128
  pre_norm: False

feature_pool:
  pool_with_resnet: False 
  pool_downsample_size: 2

clf_head:
  model_dim: 128
  num_classes: 10

optimizer:
  name: sgd
  lr: 0.1
  weight_decay: 1.e-04

scheduler:
  name: cosine
  warmup_epochs: 5

criterion:
  smoothing: 0.1

# Data
dataset:
  name: cifar10
  root: data/cifar10
  train_transform:
    random_flip:
    to_tensor:
    normalize:
      mean: [0.4914, 0.4822, 0.4465]
      std: [0.2023, 0.1994, 0.2010]
  val_transform:
    to_tensor:
    normalize:
      mean: [0.4914, 0.4822, 0.4465]
      std: [0.2023, 0.1994, 0.2010]